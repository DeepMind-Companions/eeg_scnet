% Create a document for a project proposal
\documentclass[10pt]{article}
% Packages
\usepackage{geometry}
\geometry{
    top=1.5cm,
    bottom=1.5cm,
    left=2cm,
    right=2cm
}
\usepackage{ragged2e}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{graphicx}
\usepackage{tikz}
% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
    \usepackage[T1]{fontenc}
    \usepackage[utf8]{inputenc}
    \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
    \usepackage{unicode-math}
    \defaultfontfeatures{Scale=MatchLowercase}
    \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
    \usepackage[]{microtype}
    \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
    \IfFileExists{parskip.sty}{%
        \usepackage{parskip}
    }{% else
        \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
\KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
\setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newlength{\cslentryspacingunit} % times entry-spacing
\setlength{\cslentryspacingunit}{\parskip}
\newenvironment{CSLReferences}[2] % #1 hanging-ident, #2 entry spacing
{% don't indent paragraphs
    \setlength{\parindent}{0pt}
    % turn on hanging indent if param 1 is 1
    \ifodd #1
        \let\oldpar\par
        \def\par{\hangindent=\cslhangindent\oldpar}
    \fi
    % set entry spacing
    \setlength{\parskip}{#2\cslentryspacingunit}
}%
{}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}\break}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}
\ifLuaTeX
    \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
    hidelinks,
pdfcreator={LaTeX via pandoc}}

% Title
\title{\textbf{Design \& Analysis of Algorithms Report \\ \vspace{5mm} EEG classification using Deep Learning Algorithms}}
\author{\textbf{Team Members} \vspace{1mm} \\ Muhammad Athar (408369) \\ Muhammad Arsalan Khan (410963) \vspace{5mm} \\ \textbf{Class: }BESE - 13A}

\begin{document}
\maketitle

\tableofcontents
\newpage

\justifying
\section{Introduction}
The semester project for Design and Analysis of Algorithms aims to tackle the problem of classifying EEG (Electroencephalography) files as either normal or abnormal.
Electroencephalography (EEG) is a non-invasive method used to record electrical activity of the brain. However, manual analysis of EEG data is time consuming and requires expertise of highly trained neurologists. Unfortunately, there is a lack of clinically certified neurologists in developing countries especially in Pakistan. Therefore, the aim of this project is to develop a deep learning model that can classify EEG files as either normal or abnormal. Such deep learning model would help in the initial screening of EEG files and would reduce the workload of neurologists.

\subsection{Timeline}
The project is estimated to take a further of 2-3 months to be completely finalized. However, our first model of SCNet had been prepared and trained upon.
The timeline for the project is as follows:

\begin{center}
\begin{tikzpicture}
        
\draw (0,0) -- (12,0);
\foreach \x in {1,4,7,10}
    \draw (\x cm,3pt) -- (\x cm,-3pt);


% Adding All the events
\draw (1,0) node[below=3pt] {\scriptsize End of May} node[above=3pt, text width=3cm, align=center] {\tiny Initital Research Completed};
\draw (4,0) node[below=3pt] {\scriptsize Mid June} node[above=3pt, text width=3cm, align=center] {\tiny Literature Models Reviewed and Tested};
\draw (7,0) node[below=3pt] {\scriptsize End of June} node[above=3pt, text width=3cm, align=center] {\tiny Initial Models drafted and tested};
\draw (10,0) node[below=3pt] {\scriptsize July} node[above=3pt, text width=3cm, align=center] {\tiny Comparison of Models and Final Model Selection};


\end{tikzpicture}
\end{center}

\begin{itemize}
    \item \textbf{End of May:} The initital research on EEG Classification using deep learning technique is already complete.
    \item A single model has also been prepared in tensorflow replicating the SCNet implementation.
    \item \textbf{June Beginning:} At the start of june, most models that are present in the literature will be replicated and tested locally on multiple datasets.
    \item \textbf{Mid June:} New implementations of the model will be finalized and worked upon. They will also be tested on multiple datasets.
    \item \textbf{End of June:} The models will be compared to find the best performing models and to evaluate the results.
\end{itemize}














\section{Contributions} 

\subsection{ResNet18 Algorithm}
In most of the algorithms that are used to classify EEG signals, it was found out that features from different levels of abstractions seemed to be useful to accurately classify the EEG data. Hence, for this purpose, we decided to implement the ResNet18 architecture to classify our EEG data.
\begin{enumerate}
    \item The ResNet Algorithm used data that was already preprocessed and saved in NPZ file format.
    \item The model contained a basic block that had 2 convolutional layers, followed by a batch normalization layer and a ReLU activation function.
    \item The model then contained 4 residual blocks, each containing 2 convolutional layers, followed by a batch normalization layer and a ReLU activation function.
    \item The skip connections were added to the output of the residual blocks.
\end{enumerate}

\subsection{Equations}
\[
\text{output} = \text{input} + \text{F}(\text{input})
\]
Above equation represents the skip connection (identity mapping).

\[
\text{Conv}(x, W) = \sum_{i=1}^{N} x_i \ast W_i + b
\]
This just shows the basic convolutional block.

\[
\text{output} = \text{ReLU}(\text{BN}(\text{Conv}(\text{ReLU}(\text{BN}(\text{input})))))
\]
The entire residual block can be represented by the above equation.

\subsection{Diagrams}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{resnet.png}
    \caption{ResNet Architecture}
    \label{fig:resnet_arch}
\end{figure}
The ResNet architecture is shown in Figure \ref{fig:resnet_arch}. It contains a basic block followed by 4 residual blocks. The skip connections are added to the output of the residual blocks.


\subsection{Pseudocodes}
\begin{algorithm}[H]
  \caption{Basic Block for ResNet}
  \begin{algorithmic}[1]
    \Procedure{BasicBlock}{in\_planes, planes, stride}
      \State expansion $\gets 1$
      \State
      \State Initialize: conv1, bn1, conv2, bn2
      \State
      \State $x \gets$ Conv2d(in\_planes, planes, kernel\_size=3, stride=stride, padding=1, bias=False) \Comment{Initialize conv1}
      \State $x \gets$ BN(x) \Comment{Apply Batch Normalization}
      \State $x \gets$ ReLU(x) \Comment{Apply ReLU activation}
      \State
      \State $x \gets$ Conv2d(planes, planes, kernel\_size=3, stride=1, padding=1, bias=False) \Comment{Initialize conv2}
      \State $x \gets$ BN(x) \Comment{Apply Batch Normalization}
      \State
      \State \textbf{if} stride $\neq 1$ or in\_planes $\neq$ expansion $\cdot$ planes:
      \State \hspace{1cm} $shortcut \gets$ Conv2d(in\_planes, expansion $\cdot$ planes, kernel\_size=1, stride=stride, bias=False) \Comment{Initialize shortcut}
      \State \hspace{1cm} $shortcut \gets$ BN(shortcut) \Comment{Apply Batch Normalization}
      \State
      \State $x \gets$ $x +$ shortcut \Comment{Add shortcut connection}
      \State $x \gets$ ReLU(x) \Comment{Apply ReLU activation}
      \State
      \State \textbf{return} x \Comment{Return the output}
    \EndProcedure
  \end{algorithmic}
\end{algorithm}


\begin{algorithm}[H]
  \caption{ResNet}
  \begin{algorithmic}[1]
    \Procedure{ResNet}{input\_channels, block, num\_blocks, num\_classes}
      \State in\_planes $\gets 64$
      \State
      \State Initialize: conv1, bn1, layer1, layer2, layer3, layer4, max\_pool, linear
      \State
      \State $x \gets$ Conv1(input\_channels, 64, kernel\_size=3, stride=1, padding=1) \Comment{Initialize conv1}
      \State $x \gets$ BN(x) \Comment{Apply Batch Normalization}
      \State $x \gets$ ReLU(x) \Comment{Apply ReLU activation}
      \State
      \State $x \gets$ layer1(x) \Comment{Apply layer1}
      \State $x \gets$ layer2(x) \Comment{Apply layer2}
      \State $x \gets$ layer3(x) \Comment{Apply layer3}
      \State $x \gets$ layer4(x) \Comment{Apply layer4}
      \State
      \State $x \gets$ MaxPool(x) \Comment{Apply Max Pooling}
      \State $x \gets$ Flatten(x) \Comment{Flatten the output}
      \State $x \gets$ Linear(x, num\_classes) \Comment{Apply Linear layer for classification}
      \State
      \State \textbf{return} x \Comment{Return the output}
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
  \caption{\_make\_layer}
  \begin{algorithmic}[3]
    \Procedure{\_make\_layer}{block, planes, num\_blocks, stride}
      \State Initialize strides and layers
      \State
      \For {stride in strides}
        \State Add block to layers
        \State Update in\_planes
      \EndFor
      \State
      \State \textbf{return} layers
    \EndProcedure
  \end{algorithmic}
\end{algorithm}


\subsection{Temporal Net Algorithm}
Another algorithm we implemented was using TCN (Temporal Convolutional Networks) to classify EEG signals. Literature showed that the temporal features in the EEG data gave important information on whether the EEG is normal or abnormal.

\begin{enumerate}
    \item The Temporal Net Algorithm used data that was already preprocessed and saved in NPZ file format.
    \item The model used causal convolutions to capture the temporal dependencies in the EEG data.
    \item The model used dilated convolutions to increase the receptive field of the network.
    \item The model used a softmax classifier to classify the EEG data.
\end{enumerate}

\subsection{Equations}
\[
y_t = \sum_{k=1}^{K} w_k \cdot x_{t-k}
\]
This equation represents the operation of a temporal convolutional layer, where \( y_t \) is the output at time step \( t \), \( x_{t-k} \) is the input at time step \( t-k \), \( w_k \) are the convolutional weights, and \( K \) is the kernel size.

\[
y_t = \sum_{k=1}^{K} w_k \cdot x_{(d \cdot t) - k}
\]
In this equation, \( d \) is the dilation factor, which controls the spacing between elements in the convolutional kernel.

\subsection{Diagrams}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{temporal.png}
    \caption{Temporal Net Block Architecture}
    \label{fig:temporal_arch}
\end{figure}
The Temporal block is shown in Figure \ref{fig:temporal_arch}. This shows how time based data is collected from previous layers and input into the next layers.

\subsection{Pseudocodes}
\begin{algorithm}[H]
  \caption{CausalConv1d}
  \begin{algorithmic}[1]
    \Procedure{CausalConv1d}{in\_channels, out\_channels, kernel\_size, dilation=1}
      \State \textbf{Input:} in\_channels, out\_channels, kernel\_size, dilation
      \State \textbf{Output:} Causal convolution layer

      \State Calculate padding: padding $\gets$ (kernel\_size - 1) * dilation

      \State Initialize convolution layer: conv $\gets$ Conv1d(in\_channels, out\_channels, kernel\_size, padding=padding, dilation=dilation)

      \State \textbf{return} conv
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
  \caption{TcnEEGModel Architecture}
  \begin{algorithmic}[1]
    \Procedure{TcnEEGModel}{in\_channels, input\_features, output\_size}
      \State \textbf{Input:} in\_channels, input\_features, output\_size
      \State \textbf{Output:} TCN-based EEG model
      
      \State Initialize conv1 with Conv1d(in\_channels, 32, kernel\_size=3, padding=2, dilation=1)
      \State Initialize conv2 with Conv1d(in\_channels, 32, kernel\_size=3, padding=4, dilation=2)
      \State Initialize residual1 with Conv1d(in\_channels, 64, kernel\_size=1)
      \State Initialize conv3 with Conv1d(in\_channels, 32, kernel\_size=3, padding=8, dilation=4)
      \State Initialize conv4 with Conv1d(in\_channels, 32, kernel\_size=3, padding=16, dilation=8)
      \State Initialize residual2 with Conv1d(64, 32, kernel\_size=1)
      \State Initialize linear with Linear(64, 1)
      
      \State \textbf{return} TCN-based EEG model

      \State \textbf{Forward Pass:}
      \State \hspace{0.5cm} residual = src
      
      \State \hspace{0.5cm} src = conv1(src)
      \State \hspace{0.5cm} src = conv2(src)
      \State \hspace{0.5cm} src += residual1(residual) \Comment{Residual connection}
      \State \hspace{0.5cm} residual = src
      
      \State \hspace{0.5cm} src = conv3(src)
      \State \hspace{0.5cm} src = conv4(src)
      \State \hspace{0.5cm} src += residual2(residual) \Comment{Residual connection}
      
      \State \hspace{0.5cm} src = src.squeeze(1)
      \State \hspace{0.5cm} src = src.permute(0,2,1)
      \State \hspace{0.5cm} src = torch.mean(src, dim=1)
      \State \hspace{0.5cm} src = linear(src)
      \State \hspace{0.5cm} src = torch.sigmoid(src)
      \State \hspace{0.5cm} \textbf{return} src \Comment{Returns the output of the model}
    \EndProcedure
  \end{algorithmic}
\end{algorithm}





\subsection{SCNet Algorithm} 
\begin{enumerate}
  \item The first step of the algorithm involves preprocessing the raw EEG recordings to make them suitable for training. The preprocessing steps involve:
  \begin{itemize}
    \item Selection of 21 standard channels that exist in all EEG recordings.
    \item Downsampling the EEG recordings to 100 Hz.
    \item Clipping the absolute amplitude between the range 0 to 100 $\mu$V.
    \item Taking the part of the recording from the start of 1st minute to the end of the 7th minute.
  \end{itemize}
  \item The second step of the algorithm involves extracting spatial features from the preprocessed EEG recordings. It is done so by taking the average, maximum, and standard deviation across all channels, and appending them to the feature vector. At this point, the shape of the training data is (24, length of recording).
  \item The third step of the algorithm involves extracting temporal features. By using multiple 1D convolutional layers inside Multi-feature fusion modules(MFFM). The MFFM uses skip connections between two consecutive convolutional layers for the fusion of characteristics from different network layers.
  \item After passing through all these convolutional layers, the output is passed through a global average pooling layer and a softmax layer is applied to get the final output.
  \item The model is trained using the Adam optimizer with a learning rate of 1e-3 and a batch size of 32. The model is trained for 60 epochs.
\end{enumerate}

\subsection{Equations}
\[ s_{gap}^t = \frac{1}{C} \sum_{c=1}^{C} x_{ct} \]
Above equation is used to calculate the average of the EEG data across all channels at time t.

\[ s_{gmp}^t = max\{x_{ct}\} \]
Above equation is used to calculate the maximum value of the EEG data across all channels at time t.

\[ s_{gsp}^t = \frac{1}{C} \sqrt{\sum_{c=1}^{C} (x_{ct} - s_{gap}^t)^2} \]
Above equation is used to calculate the standard deviation of the EEG data across all channels at time t.
\newline
All the above equations are used to calculate values for all times t=1,2,...,T. C = 21 is the number of channels selected.

\subsection{Diagrams}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{silm.png}
    \caption{Spatial Information Learning Module (SILM)}
\end{figure}
Figure 1 shows that SILM applies GSP(Global standard deviation Pooling), GAP(Global Average Pooling), and GMP(Global Max Pooling) across all channels, followed by a dropout layer of 0.05 on each. They are then concatenated.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.4\textwidth]{mffm.png}
    \caption{Multi-feature Fusion Module (MFFM)}
\end{figure}
Figure 2 shows that the MFFM involves two consecutive 1D convolutional layers, followed by Batch Normalization and ReLU activation function on each. Before applying the next convolutional layer, the output of the previous layer is concatenated.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.59\textwidth]{model.png}
    \caption{SCNet Architecture}
\end{figure}
Figure 3 shows that the entire SCNet architecture, with Average and Max Pooling in between layers, to reduce the input dimensions at each stage. At the end, a softmax classifier is used to classify the EEG data.

\subsection{Pseudocodes}

\begin{algorithm}[H]
  \caption{Preprocessing}
      \begin{algorithmic}[1]
      \Procedure{Preprocess}{Raw EEG} \Comment{The Raw EEG is input}
          \State Total Channels $\gets 21$
          \State Input Format: Raw EEG Data
          \State 
          \State Output Format: Preprocessed EEG Data
          \State
  
          \State Output $\gets$ \Call{selectChannels}{Raw EEG, 21} \Comment{Select 21 Standard channels}
          \State Output $\gets$ \Call{downsample}{Output, 100 Hz} \Comment{Downsample to 100 Hz}
          \State Output $\gets$ \Call{clipAmplitude}{Output, 0, 100 $\mu$V} \Comment{Clip amplitude between 0 to 100 $\mu$V}
          \State Output $\gets$ \Call{selectTime}{Output, 1st to 8th minute} \Comment{Select 1st minute to 8th minute}
          \State \textbf{return} Output \Comment{Returns the preprocessed data} 
      \EndProcedure
      \end{algorithmic}
  \end{algorithm}

\begin{algorithm}[H]
\caption{SILM}
    \begin{algorithmic}[2]
    \Procedure{Classify}{Preprocessed EEG} \Comment{The preprocessed EEG is input}
        \State Total Channels $\gets 21$
        \State Input Format: EEG data $[e_{ij}]$ where $i \gets 1$ to $21$ where 21 is the number of channels
        \State and $j \gets 1$ to $n$ where $n$ is the number of timestamps
        \State 
        \State Output Format: The EEG data with concatenated GAP, GMP, and GSP
        \State

        \State Output $\gets$ \Call{Preprocess}{Raw EEG} \Comment{Preprocess the Raw EEG}
        \State Output $\gets$ \Call{SpatialFeatures}{Output}
        \State Output $\gets$ \Call{TemporalFeatures}{Output}
        \State Class $\gets$ \Call{Classify}{Output}
        \State \textbf{return} Class\Comment{Returns the class of the classified EEG}
        \EndProcedure
    \end{algorithmic}
\end{algorithm}

\begin{algorithm}
    \caption{Temporal Net Algorithm}
    \begin{algorithmic}[1]
        \Procedure{Classify}{Raw EEG} \Comment{The Raw EEG is input}
        \State Total Channels $\gets 21$
        \State Input Format: EEG data Channels $[e_i]$ where $i \gets 0$ to $21$
        \State $e_i \gets [e_j]$ where $j \gets 0$ to $n$ where $n$ is the number of timestamps
        \State 
        \State Output Format: Class of the EEG in binary (Abnormal/Normal)
        \State

        \State Output $\gets$ \Call{Preprocess}{Raw EEG} \Comment{Preprocess the Raw EEG}
        \State Output $\gets$ \Call{TemporalFeatures}{Output}
        \State Class $\gets$ \Call{Classify}{Output}
        \State \textbf{return} Class\Comment{Returns the class of the classified EEG}
        \EndProcedure
        \State GAP out $\gets$ \Call{GAP}{Preprocessed EEG} \Comment{Global Average Pooling}
        \State GMP out $\gets$ \Call{GMP}{Preprocessed EEG} \Comment{Global Max Pooling}
        \State GSP out $\gets$ \Call{GSP}{Preprocessed EEG} \Comment{Global Standard Deviation Pooling}
        \State Preprocessed EEG $\gets$ \Call{Concat}{Preprocessed EEG, GAP out, GMP out, GSP out} \Comment{Concatenate the outputs}
        \State \textbf{return} Preprocessed EEG \Comment{Returns the preprocessed EEG with concatenated features}
    \EndProcedure
    \end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
  \caption{1D Convolutional Layer}
  \begin{algorithmic}[3]
      \Procedure{Conv1D}{data, kernel, stride}
      \State Input Format: $[e_{ik}]$ where $i \gets 0$ to $h_0$ and $k \gets 0$ to $w_0$
      \State Output Format: $[o_{ij}]$ where $i \gets 0$ to $h_0$, $j \gets 0$ to $w_1$

      \Comment The height of the data remains the same
      \State $w_0 \gets width$, $h_0 \gets height$
      \State $w_1 \gets \frac{w_0 - kernel}{stride} + 1$  \Comment Calculate the width of the output
      \State for $i \gets 0$ to $h_0$ do
      \State \hspace{1cm} for $j \gets 0$ to $w_1$ do
      \State \hspace{2cm} $[o_{ij}] \gets \sum_{k=j*stride}^{j*stride + kernel} [w_{ik}] * [e_{ik}] + b$ \Comment{Slide the kernel through input data}
      \State \hspace{1cm} end for
      \State end for

      \State \textbf{return} $[o_{ij}]$
      \EndProcedure
  \end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
\caption{ReLU Activation Function}
    \begin{algorithmic}[4]
    \Procedure{ReLU}{data} 
          \State Input Format: $[e_{ij}]$ where $i \gets 0$ to $h$ and $j \gets 0$ to $w$
          \State 
          \State Output Format: $[o_{ij}]$ where $i \gets 0$ to $h$ and $j \gets 0$ to $w$
          \State
          \State for $i \gets 0$ to $h$ do
          \State \hspace{1cm} for $j \gets 0$ to $w$ do
          \State \hspace{2cm} $[o_{ij}] \gets max(0, [e_{ij}])$ \Comment{Apply ReLU activation function}
          \State \hspace{1cm} end for
          \State end for
          \State \textbf{return} $[o_{ij}]$ \Comment{Returns the output after applying ReLU}
    \EndProcedure
    \end{algorithmic}

\end{algorithm}

\begin{algorithm}[H]
  \caption{Batch Normalization}
      \begin{algorithmic}[4]
      \Procedure{BatchNorm}{data} 
          \State Input Format: $[e_{ij}]$ where $i \gets 0$ to $h$ and $j \gets 0$ to $w$
          \State
          \State Output Format: $[o_{ij}]$ where $i \gets 0$ to $h$ and $j \gets 0$ to $w$
          \State
          \State $\mu \gets \frac{1}{h*w} \sum_{i=0}^{h} \sum_{j=0}^{w} [e_{ij}]$ \Comment{Calculate the mean}
          \State $\sigma^2 \gets \frac{1}{h*w} \sum_{i=0}^{h} \sum_{j=0}^{w} ([e_{ij}] - \mu)^2$ \Comment{Calculate the variance}
          \State $[o_{ij}] \gets \frac{[e_{ij}] - \mu}{\sqrt{\sigma^2 + \epsilon}}$ \Comment{Normalize the data}
          \State \textbf{return} $[o_{ij}]$ \Comment{Returns the output after applying Batch Normalization}
      \EndProcedure
      \end{algorithmic}
      
  \end{algorithm}


  \begin{algorithm}[H]
    \caption{Multi-feature Fusion Module}
        \begin{algorithmic}[5]
        \Procedure{MFFM}{data} \Comment{The Raw EEG is input}
            \State Input Format: $[e_{ij}]$ where $i \gets 0$ to $h$ and $j \gets 0$ to $w$
            \State
            \State Output Format: $[o_{ij}]$ where $i \gets 0$ to $h$ and $j \gets 0$ to $w$
            \State
            \State x1 $\gets$ \Call{Conv1D}{data, 8, 5} \Comment{Apply 1D Convolutional Layer}
            \State x1 $\gets$ \Call{BatchNorm}{x1} \Comment{Apply Batch Normalization}
            \State x1 $\gets$ \Call{ReLU}{x1} \Comment{Apply ReLU Activation Function}
            \State x2 $\gets$ \Call{Concat}{x1, data} \Comment{Concatenate the output with the input}
            \State x2 $\gets$ \Call{Conv1D}{x2, 16, 5} \Comment{Apply 1D Convolutional Layer}
            \State x2 $\gets$ \Call{BatchNorm}{x2} \Comment{Apply Batch Normalization}
            \State x2 $\gets$ \Call{ReLU}{x2} \Comment{Apply ReLU Activation Function}
            \State Output $\gets$ \Call{Concat}{data, x1, x2} \Comment{Concatenate the result at all three stages}
            \State \textbf{return} Output \Comment{Returns the output}
        \EndProcedure

    \end{algorithmic}
\end{algorithm}
        

    \begin{algorithm}[H]
      \caption{Softmax Layer}
          \begin{algorithmic}[7]
          \Procedure{Softmax}{data} 
              \State Input Format: $[e_{i}]$ where $i \gets 0$ to $num\_classes$
              \State
              \State Output Format: $[o_{i}]$ where $i \gets 0$ to $num\_classe$
              \State
              \State for $i \gets 0$ to $num\_classes$ do
              \State \hspace{1cm} $Output_i$ $\gets \frac{e^{[data_{i}]}}{\sum_{j=0}^{num\_classes} e^{[data_{j}]}}$ \Comment{Apply Softmax}
              \State \textbf{return} Output \Comment{Returns the output after applying Softmax}
          \EndProcedure
          \end{algorithmic}
          
      \end{algorithm}

      \begin{algorithm}[H]
        \caption{SCNet Architecture}
            \begin{algorithmic}[8]
            \Procedure{SCNet}{Preprocessed EEG}
                \State Total Channels $\gets 21$
                \State Input Format: EEG data Channels $[e_i]$ where $i \gets 0$ to $21$
                \State $e_i \gets [e_j]$ where $j \gets 0$ to $n$ where $n$ is the number of timestamps
                \State 
                \State Output Format: Class of the EEG in binary (Abnormal/Normal)
                \State
                \State x $\gets$ \Call{SILM}{Preprocessed EEG} \Comment{Apply SILM}
                \State x1 $\gets$ \Call{AvgPool}{x, 3} \Comment{AvgPool with stride 3}
                \State x2 $\gets$ \Call{MaxPool}{x, 3}  \Comment{MaxPool with stride 3}
                \State x $\gets$ \Call{Concat}{x1, x2} \Comment{Concatenate the outputs}
                \State x $\gets$ \Call{BatchNorm}{x} \Comment{Apply Batch Normalization}
                \State x1 $\gets$ \Call{MFFM}{x} \Comment{Apply MFFM}
                \State x2 $\gets$ \Call{MFFM}{x} \Comment{Apply MFFM}
                \State x $\gets$ \Call{SpatialDropout}{x1 + x2, 0.5} \Comment{Apply Spatial Dropout}
                \State x $\gets$ \Call{MaxPool}{x, 2} \Comment{MaxPool with stride 2}
                \State x $\gets$ \Call{Conv1D}{x, 32, 3}
                \State x $\gets$ \Call{BatchNorm}{x} \Comment{Apply Batch Normalization}
                \State x $\gets$ \Call{ReLU}{x} \Comment{Apply ReLU Activation Function}
                \State x1 $\gets$ \Call{MFFM}{x} \Comment{Apply MFFM}
                \State x2 $\gets$ \Call{MFFM}{x} \Comment{Apply MFFM}
                \State x $\gets$ \Call{Conv1D}{x1 + x2, 32, 3}
                \State x $\gets$ \Call{BatchNorm}{x} \Comment{Apply Batch Normalization}
                \State x $\gets$ \Call{MFFM}{x} \Comment{Apply ReLU Activation Function}
                \State x $\gets$ \Call{MaxPool}{x, 2} \Comment{MaxPool with stride 2}
                \State x $\gets$ \Call{Conv1D}{x, 32, 3}
                \State x $\gets$ \Call{BatchNorm}{x} \Comment{Apply Batch Normalization}
                \State x $\gets$ \Call{GAP}{x} \Comment{Apply Global Average Pooling}
                \State x $\gets$ \Call{Dense}{x, 2}
                \State x $\gets$ \Call{Softmax}{x} \Comment{Apply Softmax}
            \EndProcedure
            \end{algorithmic}
            
        \end{algorithm}

\subsection{Problems Encountered}
One of the main problem we encountered is in the training of the model. Even after obtaining computational resources, the dataset (TUH EEG Corpus) was still very large (About 50 GB) which can't be loaded into the RAM all at once and trained on. For this we started preprocessing the data and storing it in tf records. This helped in training the model by loading the data on the fly.
However, even after we trained the model, we encountered another setback, which was that we were uanble to get a good performance on the evaluation set, even though it was giving accuracies upto 99\% on the training data. The accuracy on the evaluation set never went above 50\%. We are still trying to resolve this issue till date.


\section{Conclusion}
In conclusion, the SCNet model has been chosen for the classification of EEG files as it has shown to be effective in classifying EEG files into normal and abnormal. The model is light-weight and has a high accuracy of 90.57\%. (Wu et al., 2023)

\section{Reference}
\hypertarget{refs}{}
\begin{CSLReferences}{1}{0}
    \leavevmode\vadjust pre{\hypertarget{ref-WU2023105059}{}}%
    Wu, Tao, Yujie Fan, Yunning Zhong, Xiu Cheng, Xiangzeng Kong, and Lifei
    Chen. 2023. {``SCNet: A Spatial Feature Fused Convolutional Network for
    Multi-Channel EEG Pathology Detection.''} \emph{Biomedical Signal
    Processing and Control} 86: 105059.
    \url{https://doi.org/10.1016/j.bspc.2023.105059}.

\end{CSLReferences}

\end{document}
