{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db952cea-da10-46c2-a432-7ccd3bc19676",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# train_folder = \"../../../Datasets/dataset_pickle/test/train/\"\n",
    "# eval_folder = \"../../../Datasets/dataset_pickle/test/eval/\"\n",
    "\n",
    "# train_folder = \"../data/test/train/\"\n",
    "# eval_folder = \"../data/test/eval/\"\n",
    "\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 2\n",
    "hidden_size = 10\n",
    "output_size = 1  # Binary classification\n",
    "number_of_eeg_channels = 8\n",
    "eval_batch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e0dd7b63-9abb-4c1f-9917-1f70dd0b3558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Block for ResNet\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion * planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm3d(self.expansion * planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# ResNet\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, input_channels, block, num_blocks, num_classes=1000):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(input_channels, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d((1, 1))\n",
    "        self.linear = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.max_pool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet18(input_channels):\n",
    "    return ResNet(input_channels,BasicBlock, [2, 2, 2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "87debc6e-dc10-4d57-81c9-dbaf123d3364",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetEEG18(nn.Module):\n",
    "    def __init__(self, input_channels):\n",
    "        super(ResNetEEG18, self).__init__()\n",
    "        self.resnet18 = ResNet18(input_channels)\n",
    "\n",
    "        '''\n",
    "        '''\n",
    "\n",
    "        \n",
    "        self.linear = nn.Linear(1000, 1)\n",
    "\n",
    "    def forward(self, src):\n",
    "        src = self.resnet18(src)\n",
    "        src = self.linear(src)\n",
    "        src = torch.sigmoid(src)\n",
    "        return src\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "70a6ac95-4706-4f31-b093-8ec950176c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "demo_data = torch.rand(1, 3, 12, 60)\n",
    "\n",
    "resneteegmodel = ResNetEEG18(3)\n",
    "\n",
    "output = resneteegmodel(demo_data)\n",
    "output\n",
    "\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748b618b-7889-46cb-878e-4db30991fff0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2944cea6-c5af-4e87-b366-45dc20a80db7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0be041-477a-4d84-ba43-3a58af0f41f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d573fe-bb41-4e9c-b40c-7a8c5a2d339b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e2080f-d706-49e7-a833-ccc30f4277b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5c889c-84f6-49c6-9791-5c5c374366f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6cfa1c-8730-4c11-a18d-a593986938d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685164e3-b38e-45cd-8d52-bac7a5f695ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff305f6-e165-4940-acde-8947699c71df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef63352-d31b-468e-bf7c-e2c36644ac38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a60f72-e4c8-4ae3-b559-4167138abbca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7aa9a2-b04c-403c-bffc-78f3baf3b7b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ef40b4-f4f2-40fa-96ac-6b2423f411a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0223c275-6db6-4ce0-a1ae-41f12b0bd43f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce1b356-7c23-4f27-b63b-589b8fed3637",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f59eabc-7ecd-4c73-8863-fc5a4cd90e07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d690436-a90c-4ddf-be99-b6fe873d9476",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30ce3c8-c352-488a-9b0a-76865b2b760b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96230ca9-0118-4268-894b-f17e8121c2c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e23df91-ad0b-4dac-976c-35da26977375",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454f7e26-50af-4295-b6a0-5d18749cc92f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abb2b5a-8976-42b2-a5ac-4db20bf610e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previous implementation\n",
    "# Create a simple 1D convolutional neural network model\n",
    "class ConvEEGModel(nn.Module):\n",
    "    def __init__(self, input_channels, input_features, output_size):\n",
    "        super(ConvEEGModel, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.utils.weight_norm(nn.Conv1d(input_channels, 32, 3, padding = 2, dilation=1), dim = None),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.utils.weight_norm(nn.Conv1d(32, 16, 3, padding = 4, dilation=2), dim = None),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "        self.residual1 = nn.Conv1d(input_channels, 16, kernel_size = 1, padding = 3)\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.utils.weight_norm(nn.Conv1d(16, 8, 3, padding = 8, dilation=4), dim = None),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.utils.weight_norm(nn.Conv1d(8, 4, 3, padding = 16, dilation=8), dim = None),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "        self.residual2 = nn.Conv1d(16, 4, kernel_size = 1, padding = 12)\n",
    "        self.linear = nn.Linear(4, 1)\n",
    "\n",
    "    def forward(self, src):\n",
    "\n",
    "        residual = src.clone()\n",
    "        \n",
    "        src = self.conv1(src)\n",
    "        src = self.conv2(src)\n",
    "        src += self.residual1(residual)\n",
    "\n",
    "        residual = src.clone()\n",
    "\n",
    "\n",
    "        src = self.conv3(src)\n",
    "        src = self.conv4(src)\n",
    "        src += self.residual2(residual)\n",
    "\n",
    "        src = src.squeeze(1)\n",
    "        src = src.permute(0,2,1)\n",
    "        src = torch.mean(src, dim=1)\n",
    "        src = self.linear(src)\n",
    "        src = torch.sigmoid(src)\n",
    "        return src\n",
    "\n",
    "\n",
    "        # # print(x.shape)\n",
    "        # x = self.conv1d(x)\n",
    "        # # print(x.shape)\n",
    "        # x = self.relu(x)\n",
    "        # # print(x.shape)\n",
    "        # x = self.flatten(x)\n",
    "        # # print(x.shape)\n",
    "        # x = self.fc1(x)\n",
    "        # # print(x.shape)\n",
    "        # x = self.softmax(x)\n",
    "        # # print(x.shape)\n",
    "        # return x\n",
    "\n",
    "input_channels = train_dataset.__getitem__(0)[0].shape[0]\n",
    "input_features = train_dataset.__getitem__(0)[0].shape[1]\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "# optimizer = torch.optim.AdamW(params, lr=0.0003)\n",
    "# optimizer = torch.optim.Adam(params, lr=0.0003, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "model = ConvEEGModel(input_channels, input_features, output_size)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0003)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "04207906-a5b1-4b22-a6e6-bc544b18843a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7311, 0.8808, 0.9526])\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor with some values\n",
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "\n",
    "# Apply sigmoid activation\n",
    "sigmoid_output = torch.sigmoid(x)\n",
    "\n",
    "print(sigmoid_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cf5295-6cfa-49e9-9fa8-7b38d426ce78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b7ce641d-1bcb-4084-b4e4-d807fbf19d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: torch.Size([8, 10, 12, 60])\n",
      "Output Shape: torch.Size([8, 1000])\n"
     ]
    }
   ],
   "source": [
    "# Create a simple dummy dataset\n",
    "demo_data = torch.randn((100, 10, 12, 60))  # 100 samples, 10 channels (RGB), 12x60 images\n",
    "demo_labels = torch.randint(0, 10, (100,))  # 10 classes\n",
    "\n",
    "demo_dataset = TensorDataset(demo_data, demo_labels)\n",
    "demo_dataloader = DataLoader(demo_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# Instantiate the ResNet model\n",
    "resnet_model = ResNetEEG18(10)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(resnet_model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# Training loop on the demo dataset\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, labels in demo_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = resnet_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Test the model on a small batch from the demo dataset\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in demo_dataloader:\n",
    "        outputs = resnet_model(inputs)\n",
    "        print(\"Input Shape:\", inputs.shape)\n",
    "        print(\"Output Shape:\", outputs.shape)\n",
    "        break  # Break after processing one batch for demonstration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
