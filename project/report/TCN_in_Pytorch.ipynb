{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99396c64-74ec-490d-9404-6890e90861e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# train_folder = \"../../../Datasets/dataset_pickle/test/train/\"\n",
    "# eval_folder = \"../../../Datasets/dataset_pickle/test/eval/\"\n",
    "\n",
    "train_folder = \"../data/test/train/\"\n",
    "eval_folder = \"../data/test/eval/\"\n",
    "\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 2\n",
    "hidden_size = 10\n",
    "output_size = 1  # Binary classification\n",
    "number_of_eeg_channels = 2\n",
    "eval_batch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "548e4ba3-8421-4fe1-a002-5fe69938d8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset class\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, folder_path):\n",
    "        self.data = self.load_data(folder_path)\n",
    "\n",
    "    def load_data(self, folder_path):\n",
    "        data = []\n",
    "        labels = []\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if file_name.endswith(\".npz\"):\n",
    "                file_path = os.path.join(folder_path, file_name)\n",
    "                data.append(file_path)\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.data[idx]\n",
    "        npz_data = np.load(file_path)\n",
    "        eeg_data = npz_data['array1'][0:number_of_eeg_channels]\n",
    "        label = npz_data['array2']\n",
    "        return torch.tensor(eeg_data, dtype=torch.float32), torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "# def collate(batch):\n",
    "#     return batch\n",
    "\n",
    "# Load data from eval and train folders\n",
    "train_dataset = EEGDataset(train_folder)\n",
    "val_dataset = EEGDataset(eval_folder)\n",
    "eval_dataset = EEGDataset(eval_folder)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)#, collate_fn=collate)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=eval_batch, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d684d786-5479-4189-837d-d985da43867b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Making a causal conv1d to later use in the conv_TCN\n",
    "\n",
    "class CausalConv1d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dilation=1):\n",
    "        super(CausalConv1d, self).__init__()\n",
    "\n",
    "        # Pad the input to ensure causality\n",
    "        padding = (kernel_size - 1) * dilation\n",
    "\n",
    "        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size, padding=padding, dilation=dilation)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "305ed898-ea19-48a5-8852-ed37fc4fe84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a TCN Block using causal networks\n",
    "\n",
    "class TcnEEGModel(nn.Module):\n",
    "    def __init__(self, in_channels, input_features, output_size):\n",
    "        super(TcnEEGModel, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.utils.weight_norm(nn.Conv1d(in_channels, 32, 3, padding = 2, dilation=1), dim = None),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.utils.weight_norm(nn.Conv1d(in_channels, 32, 3, padding = 4, dilation=2), dim = None),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "        self.residual1 = nn.Conv1d(in_channels, 64, 1)\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.utils.weight_norm(nn.Conv1d(in_channels, 32, 3, padding = 8, dilation=4), dim = None),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.utils.weight_norm(nn.Conv1d(in_channels, 32, 3, padding = 16, dilation=8), dim = None),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "        self.residual2 = nn.Conv1d(64, 32, 1)\n",
    "        self.linear = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, src):\n",
    "\n",
    "        residual = src\n",
    "        \n",
    "        src = self.conv1(src)\n",
    "        src = self.conv2(src)\n",
    "        src += self.residual1(residual)\n",
    "\n",
    "        residual = src\n",
    "\n",
    "\n",
    "        src = self.conv3(src)\n",
    "        src = self.conv4(src)\n",
    "        src += self.residual2(residual)\n",
    "\n",
    "        src = src.squeeze(1)\n",
    "        src = src.permute(0,2,1)\n",
    "        src = torch.mean(src, dim=1)\n",
    "        src = self.linear(src)\n",
    "        src = torch.sigmoid(src)\n",
    "        return src\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a07358f6-aa7a-46d4-840e-cddda3dca3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arsalan/.local/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TcnEEGModel(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv1d(2, 32, kernel_size=(3,), stride=(1,), padding=(2,))\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv1d(2, 32, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (residual1): Conv1d(2, 64, kernel_size=(1,), stride=(1,))\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv1d(2, 32, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(4,))\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (conv4): Sequential(\n",
       "    (0): Conv1d(2, 32, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(8,))\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (residual2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))\n",
       "  (linear): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_channels = train_dataset.__getitem__(0)[0].shape[0]\n",
    "input_features = train_dataset.__getitem__(0)[0].shape[1]\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "# optimizer = torch.optim.AdamW(params, lr=0.0003)\n",
    "# optimizer = torch.optim.Adam(params, lr=0.0003, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "model = TcnEEGModel(input_channels, input_features, output_size)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0003)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e1e392c-99b7-43b8-9cb3-32921bdfb93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170\n"
     ]
    }
   ],
   "source": [
    "num_training_steps = epochs * len(train_loader)\n",
    "# num_eval_steps = num_epochs * len(eval_dataloader)\n",
    "\n",
    "print(num_training_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d4a6fa3-31fa-497a-aebc-7901b82cd937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3b857bd9fee43faba36573a1e9b0b2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [32, 2, 3], expected input[1, 32, 120002] to have 2 channels, but got 32 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15949/3674859021.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0meval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_acc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mprev_eval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_eval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprev_eval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Accuracy\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprev_eval_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_15949/3674859021.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(model, data_loader, loss_fn, eval_batch)\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m       \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m       \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_batch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_15949/2882264851.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresidual1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresidual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1566\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbw_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_input_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1568\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1569\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1570\u001b[0m                 for hook_id, hook in (\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    304\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[0;32m--> 306\u001b[0;31m         return F.conv1d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    307\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [32, 2, 3], expected input[1, 32, 120002] to have 2 channels, but got 32 channels instead"
     ]
    }
   ],
   "source": [
    "def eval(model, data_loader, loss_fn,eval_batch):\n",
    "  model.eval()\n",
    "  print(len(data_loader))\n",
    "  eval_loss = 0.0\n",
    "  correct_eval = 0.0\n",
    "  # print(data_loader.shape)\n",
    "  with torch.no_grad():\n",
    "    for x, y in tqdm(data_loader):\n",
    "      file = x.to(device)\n",
    "      label = y.to(device)\n",
    "      output = model(file)\n",
    "      if(eval_batch == 1):\n",
    "        loss = loss_fn(output.squeeze(0), label)\n",
    "      else:\n",
    "        loss = loss_fn(output.squeeze(0), label.view(-1, 1))\n",
    "      eval_loss += loss.item()\n",
    "\n",
    "      preds = torch.where(output > 0.5, 1, 0).T\n",
    "      correct_eval += (preds == label).sum().item()\n",
    "      # print(correct_eval)\n",
    "\n",
    "    eval_loss = eval_loss/len(data_loader)\n",
    "    eval_acc = (correct_eval/(len(data_loader)*batch_size))\n",
    "\n",
    "  return eval_loss, eval_acc\n",
    "\n",
    "prev_eval_loss, prev_eval_acc = eval(model, val_loader, loss_fn, 1)\n",
    "print(\"Loss:\",prev_eval_loss, \"Accuracy\",prev_eval_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6ce429-ab27-4465-ac49-834fab303c33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910ea9df-124e-4fc1-92a0-5eff52a8ce70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8861b897-3d5a-4fff-9a1e-4e5678b47e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab46c41-a8f8-40f1-ba84-131868c3acf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438d1a68-46f1-4b57-abfc-ba58eae86148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple 1D convolutional neural network model\n",
    "class ConvEEGModel(nn.Module):\n",
    "    def __init__(self, input_channels, input_features, output_size):\n",
    "            super(ConvEEGModel, self).__init__()\n",
    "            self.conv1 = nn.Sequential(\n",
    "                nn.Conv1d(input_channels, 32, 3, padding=1),\n",
    "                nn.BatchNorm1d(32),\n",
    "                nn.GELU(),\n",
    "                # nn.MaxPool1d(2,2)        #16*16*16\n",
    "            )\n",
    "\n",
    "            self.conv2 = nn.Sequential(\n",
    "                nn.Conv1d(32, 64, 3, padding=1),\n",
    "                nn.BatchNorm1d(64),\n",
    "                nn.GELU(),\n",
    "                # nn.MaxPool2d((2,2), (2,2))        #32*16*16\n",
    "            )\n",
    "            self.conv3 = nn.Sequential(\n",
    "                nn.Conv2d(64, 96, 3, padding=1),\n",
    "                nn.BatchNorm2d(96),\n",
    "                nn.GELU(),\n",
    "                nn.Conv2d(96, 128, 3, padding=1),\n",
    "                nn.BatchNorm2d(128),\n",
    "                nn.GELU(),\n",
    "                # nn.MaxPool2d((2, 1), (2, 1)),  #64*8*8\n",
    "                nn.Dropout2d(0.2),\n",
    "            )\n",
    "            self.conv4 = nn.Sequential(\n",
    "                nn.Conv2d(128, 192, 3, padding=1),\n",
    "                nn.BatchNorm2d(192),\n",
    "                nn.GELU(),\n",
    "                nn.Conv2d(192, 256, 3, padding=1),\n",
    "                nn.BatchNorm2d(256),\n",
    "                nn.GELU(),\n",
    "                # nn.MaxPool2d((2, 1), (2, 1)),  # 64*4*4  \n",
    "                nn.Dropout2d(0.2),\n",
    "            )\n",
    "            self.conv5 = nn.Sequential(\n",
    "                # nn.Conv2d(256, 1, 4),\n",
    "                nn.Conv2d(256, 1, 3, padding='same'),\n",
    "                nn.BatchNorm2d(1),\n",
    "                nn.GELU(),\n",
    "            )  \n",
    "\n",
    "            self.linear = nn.Linear(64, 1)\n",
    "\n",
    "        # self.conv1d = nn.Conv1d(in_channels=input_channels, out_channels=64, kernel_size=3)\n",
    "        # self.relu = nn.ReLU()\n",
    "        # self.flatten = nn.Flatten()\n",
    "        # self.fc1 = nn.Linear(64 * (input_features - 2), output_size)\n",
    "        # self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, src):\n",
    "            src = self.conv1(src)\n",
    "            # print(src.shape)                                 # (*, 16, 32, 256)\n",
    "            src = self.conv2(src)\n",
    "            # print(src.shape)                                 # (*, 32, 16, 128)\n",
    "            # src = self.conv3(src)\n",
    "            # # print(x.shape)                                 # (*, 64, 8, 128)\n",
    "            # src = self.conv4(src)\n",
    "            # # print(x.shape)                                 # (*, 128, 4, 128)        \n",
    "            # src = self.conv5(src)\n",
    "            # print(x.shape)                                 # (*, 256, 1, 125)\n",
    "            src = src.squeeze(1)\n",
    "            # print(\"squeez\", src.shape)\n",
    "            src = src.permute(0,2,1)\n",
    "            # print(\"permute\", src.shape)\n",
    "            # src = self.encoder(src)\n",
    "            src = torch.mean(src, dim=1)\n",
    "            # print(\"mean\", src.shape)\n",
    "            src = self.linear(src)\n",
    "            src = torch.sigmoid(src)\n",
    "            # print(\"sigmoid\", src.shape)\n",
    "            # src = self.fc1(src)\n",
    "            # # print(x.shape)\n",
    "            # src = self.softmax(src)\n",
    "            return src\n",
    "\n",
    "        # # print(x.shape)\n",
    "        # x = self.conv1d(x)\n",
    "        # # print(x.shape)\n",
    "        # x = self.relu(x)\n",
    "        # # print(x.shape)\n",
    "        # x = self.flatten(x)\n",
    "        # # print(x.shape)\n",
    "        # x = self.fc1(x)\n",
    "        # # print(x.shape)\n",
    "        # x = self.softmax(x)\n",
    "        # # print(x.shape)\n",
    "        # return x\n",
    "\n",
    "input_channels = train_dataset.__getitem__(0)[0].shape[0]\n",
    "input_features = train_dataset.__getitem__(0)[0].shape[1]\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "# optimizer = torch.optim.AdamW(params, lr=0.0003)\n",
    "# optimizer = torch.optim.Adam(params, lr=0.0003, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "model = ConvEEGModel(input_channels, input_features, output_size)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0003)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
